# Project Lost Piglet (LP1): Behavioral Intelligence & ML Classification Pipeline

**Author:** Justin McCormick  
**Role:** Security Engineer & Threat Researcher  
**Status:** `MISSION COMPLETE (Phase 1)` | **Environment:** `GCP (us-east1)`

---

## üìñ Executive Summary
In modern Security Operations Centers (SOCs), alert fatigue generated by automated "background radiation" (e.g., Mirai variants, automated scanners) is a critical operational bottleneck. 

**Project Lost Piglet 1 (LP1)** is a cloud-resident sensor network and machine learning pipeline designed to solve this problem. By deploying a medium-interaction honeypot (Cowrie) on Google Cloud Platform, this project harvested real-world SSH/Telnet telemetry to establish a high-fidelity behavioral baseline. 

The resulting 14-phase analytical engine does not just collect logs; it engineers statistical features from command telemetry, applies unsupervised anomaly detection to filter out botnet noise, and isolates sophisticated, human-agentic threat actors for structured intelligence reporting.



---

## üß† Core Methodology & ML Architecture
This pipeline moves beyond reactive forensic logging into proactive, data-driven threat modeling. The behavioral classification engine (Phase III) is built on three pillars:

1. **Sentinel Triage (Isolation Forest):** Computes a behavioral fingerprint for each interactive session using engineered features like *Temporal Entropy*, *Mean Inter-Command Delay*, and *Burst Ratios*. An Isolation Forest establishes an unsupervised baseline to detect anomalous, high-risk interactive sessions.
2. **Taxonomy Clustering (K-Means):** Partitions the telemetry into distinct behavioral taxonomies based on heuristic centroids, categorizing actors into *Automated Bots*, *Human Operators*, and *AI/LLM Agents (Burst-Think)*.
3. **Analytic Justification (Decision Tree):** To prevent the classification from becoming a "black box," a Decision Tree surrogate model extracts human-readable mathematical rules, highlighting the primary feature split (e.g., Command Complexity vs. Entropy) driving the attribution.



---

## üèóÔ∏è Pipeline Manifest & Repository Structure

The architecture is fully documented within the master Jupyter Notebook, broken down into 14 modular execution phases.

| Phase | Title | Objective |
| :--- | :--- | :--- |
| **I - II** | **Ingestion & Enrichment** | Clean raw JSON telemetry and apply Geospatial/ASN attribution. |
| **III** | **Machine Learning** | Isolation Forest triage and K-Means behavioral clustering. |
| **IV - V** | **Intelligence Briefing** | Global distribution mapping and credential heatmaps. |
| **VI - VII** | **Technical Attribution** | Temporal cadence audits and SSH client (HASSH) fingerprinting. |
| **VIII** | **Threat Actor Dossier** | Consolidating behavioral and geographic data at the individual IP level. |
| **IX - XI** | **Forensics & TTPs** | MITRE ATT&CK mapping and 1D temporal forensic timelines. |
| **XII - XIV** | **Strategic Reports** | Executive summaries and infrastructure reuse correlation. |

### üìÇ Key Files in this Repository
* `ProjectLP1_ML_IntelligenceAssessment.ipynb`: The master codebase containing the end-to-end data engineering and ML pipeline.
* `ProjectLP1_IAReport.pdf`: The finalized 80+ page tactical intelligence assessment. **(Recommended reading for recruiters and engineering managers).**

---

## üõ†Ô∏è Environment & Tech Stack
* **Infrastructure:** Google Cloud Platform (e2-micro)
* **Collection:** Cowrie (SSH/Telnet Emulation)
* **Language:** Python 3.12+
* **Data Engineering Core:** `Pandas`, `NumPy`, `SciPy`
* **Machine Learning:** `Scikit-Learn`
* **Visual Analytics:** `Seaborn`, `Matplotlib`

---

## üöÄ Strategic Roadmap (Project LP2)
While LP1 successfully validated the architecture and statistical logic during a 96-hour soak period, the next deployment (Project LP2) will focus on longitudinal study. Future efforts will prioritize:
1. **Dynamic Contamination Tuning:** Transitioning from a static baseline 10% anomaly assumption to dynamic thresholding based on real-time traffic volume.
2. **Cognitive Friction Modeling:** Refining persona lures within the sensor to introduce deliberate latency and file structure complexity, aimed at frustrating automated parsers while enticing human curiosity.
3. **Predictive Modeling:** Moving beyond anomaly detection into **Survival Analysis**, modeling the "dwell-time" of attackers to predict the probability of lateral movement.

---

## üë§ About the Author & Engineering Philosophy

**Security-focused engineer with a background in military intelligence and applied analytics.** My work centers on applied AI for security operations‚Äîdesigning data pipelines, validating statistical assumptions, and stress-testing models under realistic constraints. I use modern AI-assisted tooling to accelerate development, but prioritize first-principles reasoning, verification, and system-level understanding.

I am actively interested in detection engineering, cloud security architecture, and scalable AI systems that translate threat data into defensible decisions.
